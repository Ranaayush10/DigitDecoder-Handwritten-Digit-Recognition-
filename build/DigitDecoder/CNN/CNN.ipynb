{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a78438-67ff-4e9d-a978-344dacbf6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import sys\n",
    "import cv2\n",
    "from cnn.neural_network import CNN\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "508ef508-4da2-49a6-b084-ca1d7eab9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the Arguments\n",
    "def parse_arguments():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-s\", \"--save_model\", type=int, default=-1)\n",
    "    ap.add_argument(\"-l\", \"--load_model\", type=int, default=-1)\n",
    "    ap.add_argument(\"-w\", \"--save_weights\", type=str)\n",
    "    \n",
    "    # If running in a Jupyter notebook or interactive environment\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        args = ap.parse_args([])\n",
    "    else:\n",
    "        args = ap.parse_args()\n",
    "    \n",
    "    return vars(args)\n",
    "\n",
    "args = parse_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b78e65b-794c-4495-8d83-26bcdef8bf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST Dataset...\n",
      "MNIST data loaded and reshaped.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Loading MNIST Dataset...')\n",
    "# Fetch the MNIST dataset\n",
    "dataset = fetch_openml('mnist_784', parser='auto')\n",
    "\n",
    "# Access data and target\n",
    "X, y = dataset['data'].to_numpy(), dataset['target'].to_numpy()\n",
    "\n",
    "# Convert the target to integer type if necessary\n",
    "\n",
    "\n",
    "# Reshape the data to (n_samples, 28, 28)\n",
    "mnist_data = X.reshape((X.shape[0], 28, 28, 1))\n",
    "\n",
    "# Add a new axis to the data to match the expected input shape for certain models\n",
    "mnist_data = mnist_data[:, :, :, :]\n",
    "\n",
    "print(\"MNIST data loaded and reshaped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f854db63-c48b-4d22-a60b-d0e6c82b8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, test_img, train_labels, test_labels = train_test_split(mnist_data/255.0, dataset.target.astype(\"int\"), test_size=0.1)\n",
    "\n",
    "# Now each image rows and columns are of 28x28 matrix type.\n",
    "img_rows, img_columns = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3df8d1b-d487-4d3c-b942-b901dc61f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training and testing data to 10 classes in range [0,classes] ; num. of classes = 0 to 9 = 10 classes\n",
    "total_classes = 10\t\t\t# 0 to 9 labels\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91db4652-abd2-4ddf-a536-fc6440834030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print('\\n Compiling model...')\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "clf = CNN.build(height=28, width=28, depth=1, total_classes=10, Saved_Weights_Path=args[\"save_weights\"] if args[\"load_model\"] > 0 else None)\n",
    "clf.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc9db2b3-06bc-4bb0-8927-4de0fb66c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially train and test the model; If weight saved already, load the weights using arguments.\n",
    "b_size = 128\t\t# Batch size\n",
    "num_epoch = 20\t\t# Number of epochs\n",
    "verb = 1\t\t\t# Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59ef51ab-a3dc-4091-a299-3ba9fc96fe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Model...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10), output.shape=(None, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_model\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      3\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining the Model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \t\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \t\u001b[38;5;66;03m# Evaluate accuracy and loss function of test data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating Accuracy and Loss Function...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:554\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m     )\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m     )\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 10, 10), output.shape=(None, 10)"
     ]
    }
   ],
   "source": [
    "# If weights saved and argument load_model; Load the pre-trained model.\n",
    "if args[\"load_model\"] < 0:\n",
    "\tprint('\\nTraining the Model...')\n",
    "\tclf.fit(train_img, train_labels, batch_size=b_size, epochs=num_epoch,verbose=verb)\n",
    "\t\n",
    "\t# Evaluate accuracy and loss function of test data\n",
    "\tprint('Evaluating Accuracy and Loss Function...')\n",
    "\tloss, accuracy = clf.evaluate(test_img, test_labels, batch_size=128, verbose=1)\n",
    "\tprint('Accuracy of Model: {:.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7d646-758b-4c35-872d-71c853720d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pre-trained model.\n",
    "if args[\"save_model\"] > 0:\n",
    "\tprint('Saving weights to file...')\n",
    "\tclf.save_weights(args[\"save_weights\"], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fdb2e-061f-450e-8e78-c4780bb50e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the images using OpenCV and making random selections.\n",
    "for num in np.random.choice(np.arange(0, len(test_labels)), size=(5,)):\n",
    "\t# Predict the label of digit using CNN.\n",
    "\tprobs = clf.predict(test_img[np.newaxis, num])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\n",
    "\t# Resize the Image to 100x100 from 28x28 for better view.\n",
    "\timage = (test_img[num][0] * 255).astype(\"uint8\")\n",
    "\timage = cv2.merge([image] * 3)\n",
    "\timage = cv2.resize(image, (100, 100), interpolation=cv2.INTER_LINEAR)\n",
    "\tcv2.putText(image, str(prediction[0]), (5, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "\t# Show and print the Actual Image and Predicted Label Value\n",
    "\tprint('Predicted Label: {}, Actual Value: {}'.format(prediction[0],np.argmax(test_labels[num])))cv2.imshow('Digits', image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17993aab-01b9-4845-900b-cb3492261da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f32ed-6973-4651-a0ce-20aeda740c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff908c-54f1-420e-abc4-2f44aaade126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943703be-055e-4161-8256-f8b8371ba168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
